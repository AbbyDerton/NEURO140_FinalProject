{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbbyDerton/NEURO140_FinalProject/blob/main/BERT_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yrG--E2Cd5mz"
      },
      "outputs": [],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-WWJbaUDmRGp"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import pickle # Needed to load data\n",
        "import time   # Needed to track runtimes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import digits\n",
        "import ktrain #This is sometimes difficult to load in Jupyter Notebook. May need to check that the correct version of scikit-learn is installed (I believe ktrain requires scikit-learn version 0.24)\n",
        "from ktrain import text as txt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcOZt8z9UqOa"
      },
      "source": [
        "# GPU Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FKyRs7aayS2"
      },
      "source": [
        "### If using Colab Pro, run the following block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94mQaZIKa1AR"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZy_Dz5ca1mp"
      },
      "source": [
        "### If using regular Colab, run these 3 cells instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmz9gKFNUsbW"
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pd0FPbfUsfd"
      },
      "outputs": [],
      "source": [
        "physical_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abbYxImeUsjK"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj6MiriZmdE3"
      },
      "source": [
        "# Download the Amazon and Goodreads datasets\n",
        "\n",
        "\n",
        "\n",
        "> These datasets have already been cleaned and the outcome has been defined as follows (0: 1-2 stars, 1: 4-5 stars). All digits (including written digits \"one\", \"two\", etc.) have been removed from the review text. In addition, the words \"rated\", \"rating\", \"rate\", \"star\", and \"stars\" have been removed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUEZu0oW4dY5"
      },
      "outputs": [],
      "source": [
        "goodreads_data = pd.read_csv(\"goodreads_clean_concat.csv\", engine='python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afP2W-oz4db5"
      },
      "outputs": [],
      "source": [
        "amazon_data = pd.read_csv(\"amazon_clean_concat.csv\").iloc[0:50000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogstq-Ew1FfD"
      },
      "source": [
        "# Take a look at the two datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfBikZ7p1LVv"
      },
      "outputs": [],
      "source": [
        "goodreads_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp8DgKuO1HlB"
      },
      "outputs": [],
      "source": [
        "amazon_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLqmwmei24EA"
      },
      "source": [
        "### Look at the distribution of positive and negative reviews in both dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed2buLGw27cg"
      },
      "outputs": [],
      "source": [
        "amazon_ones = 0\n",
        "for i in amazon_data[\"Rating\"]:\n",
        "  if i == 1:\n",
        "    amazon_ones = amazon_ones + 1\n",
        "amazon_ones/len(amazon_data[\"Rating\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBhnIY4F3Pg3"
      },
      "outputs": [],
      "source": [
        "goodreads_ones = 0\n",
        "for i in goodreads_data[\"Rating\"]:\n",
        "  if i == 1:\n",
        "    goodreads_ones = goodreads_ones + 1\n",
        "goodreads_ones/len(goodreads_data[\"Rating\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubb4zvW11nY-"
      },
      "source": [
        "# BERT Model\n",
        "\n",
        "\n",
        "\n",
        "> Use the BERT model included in the ktrain (v0.29.x) library which is a wrapper for TensorFlow Keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niVHSqifMxlk"
      },
      "source": [
        "## Train and test BERT Model on Amazon dataset using full reviews (Model 1):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcTi6ZaFLMpb"
      },
      "source": [
        "#### Split the datasets to training, testing, and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1VwWafYLQF2"
      },
      "outputs": [],
      "source": [
        "X_train_Amazon_full, X_val_and_test_Amazon_full, y_train_Amazon_full, y_val_and_test_Amazon_full = train_test_split(amazon_data[\"Review_Clean\"],\n",
        "                                                                                                        amazon_data[\"Rating\"],\n",
        "                                                                                                        test_size = 0.30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0DC1VM5L7ka"
      },
      "outputs": [],
      "source": [
        "X_val_Amazon_full, X_test_Amazon_full, y_val_Amazon_full, y_test_Amazon_full = train_test_split(X_val_and_test_Amazon_full,\n",
        "                                                                                                y_val_and_test_Amazon_full,\n",
        "                                                                                                test_size = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKBZbkDVM5aD"
      },
      "outputs": [],
      "source": [
        "### Create preproc and training and testing datasets     \n",
        "start = time.time()\n",
        "(x_train_fullA, y_train_fullA), (x_val_fullA, y_val_fullA), preproc_fullA = txt.texts_from_array(x_train = list(X_train_Amazon_full),\n",
        "                                                                                                 y_train = list(y_train_Amazon_full),\n",
        "                                                                                                 x_test = list(X_val_Amazon_full),\n",
        "                                                                                                 y_test = list(y_val_Amazon_full),\n",
        "                                                                                                 class_names = ['0','1'],\n",
        "                                                                                                 preprocess_mode = 'bert',\n",
        "                                                                                                 ngram_range=1,                    ### Change?\n",
        "                                                                                                 maxlen = 200)                     # Was 175          \n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd8mVxz2TBty"
      },
      "outputs": [],
      "source": [
        "### Define and train the model ###\n",
        "start = time.time()\n",
        "model_fullA = txt.text_classifier(name='bert',\n",
        "                             train_data=(x_train_fullA, y_train_fullA),\n",
        "                             preproc=preproc_fullA)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsuPyVv2VmDa"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_fullA = ktrain.get_learner(model=model_fullA,\n",
        "                             train_data=(x_train_fullA, y_train_fullA),\n",
        "                             val_data=(x_val_fullA, y_val_fullA),\n",
        "                             batch_size=16)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HePWIN5zUQCL"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_fullA.fit_onecycle(lr=2e-5,\n",
        "                     epochs=3)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test this model on the Amazon reviews"
      ],
      "metadata": {
        "id": "zUT2HuvbXkqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpH7fzSRXCjQ"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predictor_fullA = ktrain.get_predictor(learner_fullA.model, preproc_fullA)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOIqo3coXClo"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predicted_ratings_fullA = predictor_fullA.predict(list(X_test_Amazon_full))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNxL6AO1QtdS"
      },
      "outputs": [],
      "source": [
        "#How big is the test set?\n",
        "len(y_test_Amazon_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGp4D-eAQeG9"
      },
      "outputs": [],
      "source": [
        "#How many of the reviews in the test set were actually negative?\n",
        "num_neg = 0\n",
        "for i in range(len(y_test_Amazon_full)):\n",
        "  if list(y_test_Amazon_full)[i] == 0:\n",
        "    num_neg = num_neg + 1\n",
        "num_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tad-QOkEPfih"
      },
      "outputs": [],
      "source": [
        "#How many of the 7500 predictions were correct?\n",
        "num_correct = 0\n",
        "for i in range(len(predicted_ratings_fullA)):\n",
        "  if int(predicted_ratings_fullA[i]) == list(y_test_Amazon_full)[i]:\n",
        "    num_correct = num_correct + 1\n",
        "num_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O0ssXjBRS_c"
      },
      "outputs": [],
      "source": [
        "#What proportion of the predictions were correct?\n",
        "num_correct/len(list(y_test_Amazon_full))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoDxnquOQDe_"
      },
      "outputs": [],
      "source": [
        "#How many of the positive predictions were correct?\n",
        "num_1s_correct = 0\n",
        "for i in range(len(predicted_ratings_fullA)):\n",
        "  if int(predicted_ratings_fullA[i]) == list(y_test_Amazon_full)[i] and int(predicted_ratings_fullA[i]) == 1:\n",
        "    num_1s_correct = num_1s_correct + 1\n",
        "num_1s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk-LZtyNQOhf"
      },
      "outputs": [],
      "source": [
        "#How many of the negative predictions were correct?\n",
        "num_0s_correct = 0\n",
        "for i in range(len(predicted_ratings_fullA)):\n",
        "  if int(predicted_ratings_fullA[i]) == list(y_test_Amazon_full)[i] and int(predicted_ratings_fullA[i]) == 0:\n",
        "    num_0s_correct = num_0s_correct + 1\n",
        "num_0s_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PzgBFAAZfbE"
      },
      "source": [
        "## Test this model on the Goodreads reviews (Model 5):\n",
        "\n",
        "\n",
        "\n",
        "> Use the trained model above\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL5WBPmDZa0m"
      },
      "outputs": [],
      "source": [
        "# Prepare the goodreads dataset\n",
        "X_train_Goodreads_full, X_val_and_test_Goodreads_full, y_train_Goodreads_full, y_val_and_test_Goodreads_full = train_test_split(goodreads_data[\"Review_Clean\"],\n",
        "                                                                                                        goodreads_data[\"Rating\"],\n",
        "                                                                                                        test_size = 0.30)\n",
        "X_val_Goodreads_full, X_test_Goodreads_full, y_val_Goodreads_full, y_test_Goodreads_full = train_test_split(X_val_and_test_Goodreads_full,\n",
        "                                                                                                y_val_and_test_Goodreads_full,\n",
        "                                                                                                test_size = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaUbQOq5Za3R"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predictor_fullA = ktrain.get_predictor(learner_fullA.model, preproc_fullA)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px47q2RIZa5r"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predicted_ratings_fullGR = predictor_fullA.predict(list(X_test_Goodreads_full))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jkKr_g2dDNF"
      },
      "outputs": [],
      "source": [
        "#How big is the training dataset?\n",
        "len(y_test_Goodreads_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcrR_B5mdJBw"
      },
      "outputs": [],
      "source": [
        "#How many of the reviews in the test set were actually negative?\n",
        "num_neg = 0\n",
        "for i in range(len(y_test_Goodreads_full)):\n",
        "  if list(y_test_Goodreads_full)[i] == 0:\n",
        "    num_neg = num_neg + 1\n",
        "num_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gGl5ATkZa7-"
      },
      "outputs": [],
      "source": [
        "#How many of the 5357 predictions were correct?\n",
        "num_correct = 0\n",
        "for i in range(len(predicted_ratings_fullGR)):\n",
        "  if int(predicted_ratings_fullGR[i]) == list(y_test_Goodreads_full)[i]:\n",
        "    num_correct = num_correct + 1\n",
        "num_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRw8SXG1dDIf"
      },
      "outputs": [],
      "source": [
        "#What proportion of the predictions were correct?\n",
        "num_correct/len(list(y_test_Goodreads_full))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye2atxh6dDKt"
      },
      "outputs": [],
      "source": [
        "#How many of the positive predictions were correct?\n",
        "num_1s_correct = 0\n",
        "for i in range(len(predicted_ratings_fullGR)):\n",
        "  if int(predicted_ratings_fullGR[i]) == list(y_test_Goodreads_full)[i] and int(predicted_ratings_fullGR[i]) == 1:\n",
        "    num_1s_correct = num_1s_correct + 1\n",
        "num_1s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUnevcQgdI_Q"
      },
      "outputs": [],
      "source": [
        "#How many of the negative predictions were correct?\n",
        "num_0s_correct = 0\n",
        "for i in range(len(predicted_ratings_fullGR)):\n",
        "  if int(predicted_ratings_fullGR[i]) == list(y_test_Goodreads_full)[i] and int(predicted_ratings_fullGR[i]) == 0:\n",
        "    num_0s_correct = num_0s_correct + 1\n",
        "num_0s_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJSv_ygAqzJV"
      },
      "source": [
        "# Train and Test BERT Model on Goodreads Dataset (Model 3):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prMeGF42rSCr"
      },
      "source": [
        "### Start by balancing the training data to include more negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIe1Z5hVqyAM"
      },
      "outputs": [],
      "source": [
        "# Split the training data into positive and negative outputs\n",
        "data = {\"Review\": list(X_train_Goodreads_full), \"Rating\": list(y_train_Goodreads_full)}\n",
        "training_data = pd.DataFrame(data)\n",
        "neg_rows = training_data[\"Rating\"] == 0\n",
        "df_train_pos = training_data.loc[~neg_rows]\n",
        "df_train_neg = training_data.loc[neg_rows]\n",
        "# Merge the balanced data\n",
        "df_train = pd.concat([df_train_pos.sample(n = len(df_train_neg), random_state=42), df_train_neg], axis = 0)\n",
        "# Shuffle the order of training samples\n",
        "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop=True)\n",
        "print(\"Training set prevalence (n = {:d}):\".format(len(df_train)), \"{:.2f}%\".format((df_train[\"Rating\"].sum()/len(df_train))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK4wip2UqyCQ"
      },
      "outputs": [],
      "source": [
        "### Create preproc and training and testing datasets     \n",
        "(x_train_fullGR, y_train_fullGR), (x_val_fullGR, y_val_fullGR), preproc_fullGR = txt.texts_from_array(x_train = list(df_train[\"Review\"]),\n",
        "                                                                                                 y_train = list(df_train[\"Rating\"]),\n",
        "                                                                                                 x_test = list(X_val_Goodreads_full),\n",
        "                                                                                                 y_test = list(y_val_Goodreads_full),\n",
        "                                                                                                 class_names = ['0','1'],\n",
        "                                                                                                 preprocess_mode = 'bert',\n",
        "                                                                                                 ngram_range=1,                    ### Change?\n",
        "                                                                                                 maxlen = 200)                     # Was 175          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2dXEx95qyEP"
      },
      "outputs": [],
      "source": [
        "### Define and train the model ###\n",
        "start = time.time()\n",
        "model_fullGR = txt.text_classifier(name='bert',\n",
        "                             train_data=(x_train_fullGR, y_train_fullGR),\n",
        "                             preproc=preproc_fullGR)\n",
        "end = time.time()\n",
        "print(end - start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQPMYnemqyGj"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_fullGR = ktrain.get_learner(model=model_fullGR,\n",
        "                             train_data=(x_train_fullGR, y_train_fullGR),\n",
        "                             val_data=(x_val_fullGR, y_val_fullGR),\n",
        "                             batch_size=16)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kcPDK5_qyIw"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_fullGR.fit_onecycle(lr=2e-5,\n",
        "                     epochs=3)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test this model on the Goodreads data:"
      ],
      "metadata": {
        "id": "M2pDsIeBbJZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdqK_LDhqyNG"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predictor_fullGR = ktrain.get_predictor(learner_fullGR.model, preproc_fullGR)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCfQMtWJqyPr"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predicted_ratings_fullGR = predictor_fullGR.predict(list(X_test_Goodreads_full))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EakM3Bqsqyfu"
      },
      "outputs": [],
      "source": [
        "#How many reviews are in the test set:\n",
        "len(y_test_Goodreads_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1htbVM45qydC"
      },
      "outputs": [],
      "source": [
        "#How many of the reviews in the test set were actually negative?\n",
        "num_neg = 0\n",
        "for i in range(len(y_test_Goodreads_full)):\n",
        "  if list(y_test_Goodreads_full)[i] == 0:\n",
        "    num_neg = num_neg + 1\n",
        "num_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2-onnwZqySI"
      },
      "outputs": [],
      "source": [
        "#How many of the predictions were correct?\n",
        "num_correct = 0\n",
        "for i in range(len(predicted_ratings_fullGR)):\n",
        "  if int(predicted_ratings_fullGR[i]) == list(y_test_Goodreads_full)[i]:\n",
        "    num_correct = num_correct + 1\n",
        "num_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3kU61V2qyU_"
      },
      "outputs": [],
      "source": [
        "#What proportion of predictions were correct?\n",
        "num_correct/len(list(y_test_Goodreads_full))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuE5OMhBqyXb"
      },
      "outputs": [],
      "source": [
        "#How many of the positive predictions were correct?\n",
        "num_1s_correct = 0\n",
        "for i in range(len(predicted_ratings_fullGR)):\n",
        "  if int(predicted_ratings_fullGR[i]) == list(y_test_Goodreads_full)[i] and int(predicted_ratings_fullGR[i]) == 1:\n",
        "    num_1s_correct = num_1s_correct + 1\n",
        "num_1s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhGKaxDkqyae"
      },
      "outputs": [],
      "source": [
        "#How many of the negative predictions were correct?\n",
        "num_0s_correct = 0\n",
        "for i in range(len(predicted_ratings_fullGR)):\n",
        "  if int(predicted_ratings_fullGR[i]) == list(y_test_Goodreads_full)[i] and int(predicted_ratings_fullGR[i]) == 0:\n",
        "    num_0s_correct = num_0s_correct + 1\n",
        "num_0s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReRIZ7N6dDSG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQUkoiLS0NSd"
      },
      "source": [
        "# Rerun the above models, this time using concatenated reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50r5MBd-0Qns"
      },
      "source": [
        "# Train and Test Model on Concatenated Amazon Reviews (Model 2):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7JYvDrK5GIc"
      },
      "outputs": [],
      "source": [
        "X_train_Amazon_concat, X_val_and_test_Amazon_concat, y_train_Amazon_concat, y_val_and_test_Amazon_concat = train_test_split(amazon_data[\"Review_Concat\"],\n",
        "                                                                                                        amazon_data[\"Rating\"],\n",
        "                                                                                                        test_size = 0.30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulk1Ltkl5GIi"
      },
      "outputs": [],
      "source": [
        "X_val_Amazon_concat, X_test_Amazon_concat, y_val_Amazon_concat, y_test_Amazon_concat = train_test_split(X_val_and_test_Amazon_concat,\n",
        "                                                                                                y_val_and_test_Amazon_concat,\n",
        "                                                                                                test_size = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u30ux9zK5GIi"
      },
      "outputs": [],
      "source": [
        "### Create preproc and training and testing datasets     \n",
        "start = time.time()\n",
        "(x_train_concatA, y_train_concatA), (x_val_concatA, y_val_concatA), preproc_concatA = txt.texts_from_array(x_train = list(X_train_Amazon_concat),\n",
        "                                                                                                 y_train = list(y_train_Amazon_concat),\n",
        "                                                                                                 x_test = list(X_val_Amazon_concat),\n",
        "                                                                                                 y_test = list(y_val_Amazon_concat),\n",
        "                                                                                                 class_names = ['0','1'],\n",
        "                                                                                                 preprocess_mode = 'bert',\n",
        "                                                                                                 ngram_range=1,                    ### Change?\n",
        "                                                                                                 maxlen = 200)                     # Was 175          \n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nImZyPFv5wXT"
      },
      "outputs": [],
      "source": [
        "### Define and train the model ###\n",
        "start = time.time()\n",
        "model_concatA = txt.text_classifier(name='bert',\n",
        "                             train_data=(x_train_concatA, y_train_concatA),\n",
        "                             preproc=preproc_concatA)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1MQ_wJl5wXT"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_concatA = ktrain.get_learner(model=model_concatA,\n",
        "                             train_data=(x_train_concatA, y_train_concatA),\n",
        "                             val_data=(x_val_concatA, y_val_concatA),\n",
        "                             batch_size=16)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAKXqyEL1lto"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_concatA.fit_onecycle(lr=2e-5,\n",
        "                     epochs=3)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions on concatenated Amazon reviews"
      ],
      "metadata": {
        "id": "HCbWZayNcN1K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfkzQh_1FIt_"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predictor_concatA = ktrain.get_predictor(learner_concatA.model, preproc_concatA)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAtcD39RFIt_"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predicted_ratings_concatA = predictor_concatA.predict(list(X_test_Amazon_concat))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_aLY2j1FIuA"
      },
      "outputs": [],
      "source": [
        "#How many reviews were in the test set?\n",
        "len(y_test_Amazon_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQnyFTBZFIuA"
      },
      "outputs": [],
      "source": [
        "#How many of the reviews in the test set were actually negative?\n",
        "num_neg = 0\n",
        "for i in range(len(y_test_Amazon_concat)):\n",
        "  if list(y_test_Amazon_concat)[i] == 0:\n",
        "    num_neg = num_neg + 1\n",
        "num_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmhaEebtFIt_"
      },
      "outputs": [],
      "source": [
        "#How many of the predictions were correct?\n",
        "num_correct = 0\n",
        "for i in range(len(predicted_ratings_concatA)):\n",
        "  if int(predicted_ratings_concatA[i]) == list(y_test_Amazon_concat)[i]:\n",
        "    num_correct = num_correct + 1\n",
        "num_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGCcEOviFIt_"
      },
      "outputs": [],
      "source": [
        "#What proportion of predictions were correct?\n",
        "num_correct/len(list(y_test_Amazon_concat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STn_PVEFFIuA"
      },
      "outputs": [],
      "source": [
        "#How many of the positive predictions were correct?\n",
        "num_1s_correct = 0\n",
        "for i in range(len(predicted_ratings_concatA)):\n",
        "  if int(predicted_ratings_concatA[i]) == list(y_test_Amazon_concat)[i] and int(predicted_ratings_concatA[i]) == 1:\n",
        "    num_1s_correct = num_1s_correct + 1\n",
        "num_1s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEpATnXAFIuA"
      },
      "outputs": [],
      "source": [
        "#How many of the negative predictions were correct?\n",
        "num_0s_correct = 0\n",
        "for i in range(len(predicted_ratings_concatA)):\n",
        "  if int(predicted_ratings_concatA[i]) == list(y_test_Amazon_concat)[i] and int(predicted_ratings_concatA[i]) == 0:\n",
        "    num_0s_correct = num_0s_correct + 1\n",
        "num_0s_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTleJp-aIcgP"
      },
      "source": [
        "# Test the model trained on concat amazon data on concat goodreads data (Model 6):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTn5DkmG1lzB"
      },
      "outputs": [],
      "source": [
        "# Prepare the goodreads data\n",
        "X_train_Goodreads_concat, X_val_and_test_Goodreads_concat, y_train_Goodreads_concat, y_val_and_test_Goodreads_concat = train_test_split(goodreads_data[\"Review_Concat\"],\n",
        "                                                                                                        goodreads_data[\"Rating\"],\n",
        "                                                                                                        test_size = 0.30)\n",
        "X_val_Goodreads_concat, X_test_Goodreads_concat, y_val_Goodreads_concat, y_test_Goodreads_concat = train_test_split(X_val_and_test_Goodreads_concat,\n",
        "                                                                                                y_val_and_test_Goodreads_concat,\n",
        "                                                                                                test_size = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T97AkiajI6RL"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predicted_ratings_concatGR = predictor_concatA.predict(list(X_test_Goodreads_concat))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psZOJ8waI6RU"
      },
      "outputs": [],
      "source": [
        "#How many reviews were in the test set?\n",
        "len(y_test_Goodreads_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJdSfPocI6RU"
      },
      "outputs": [],
      "source": [
        "#How many of the reviews in the test set were actually negative?\n",
        "num_neg = 0\n",
        "for i in range(len(y_test_Goodreads_concat)):\n",
        "  if list(y_test_Goodreads_concat)[i] == 0:\n",
        "    num_neg = num_neg + 1\n",
        "num_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2EAf5FNI6RT"
      },
      "outputs": [],
      "source": [
        "#How many of the predictions were correct?\n",
        "num_correct = 0\n",
        "for i in range(len(predicted_ratings_concatGR)):\n",
        "  if int(predicted_ratings_concatGR[i]) == list(y_test_Goodreads_concat)[i]:\n",
        "    num_correct = num_correct + 1\n",
        "num_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZcYMPWmI6RT"
      },
      "outputs": [],
      "source": [
        "#What proportion of the predictions were correct?\n",
        "num_correct/len(list(y_test_Goodreads_concat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl343eKdI6RT"
      },
      "outputs": [],
      "source": [
        "#How many of the positive predictions were correct?\n",
        "num_1s_correct = 0\n",
        "for i in range(len(predicted_ratings_concatGR)):\n",
        "  if int(predicted_ratings_concatGR[i]) == list(y_test_Goodreads_concat)[i] and int(predicted_ratings_concatGR[i]) == 1:\n",
        "    num_1s_correct = num_1s_correct + 1\n",
        "num_1s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1COaApeI6RT"
      },
      "outputs": [],
      "source": [
        "#How many of the negative predictions were correct?\n",
        "num_0s_correct = 0\n",
        "for i in range(len(predicted_ratings_concatGR)):\n",
        "  if int(predicted_ratings_concatGR[i]) == list(y_test_Goodreads_concat)[i] and int(predicted_ratings_concatGR[i]) == 0:\n",
        "    num_0s_correct = num_0s_correct + 1\n",
        "num_0s_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6eu1nd1Ovf4"
      },
      "source": [
        "# Train and Test a BERT Model on the Concat Goodreads Data (Model 4):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PISCaRdiPb73"
      },
      "source": [
        "## Start by balancing the training data to include more negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYb2M7GFPsNS"
      },
      "outputs": [],
      "source": [
        "# Split the training data into positive and negative outputs\n",
        "data = {\"Review\": list(X_train_Goodreads_concat), \"Rating\": list(y_train_Goodreads_concat)}\n",
        "training_data = pd.DataFrame(data)\n",
        "neg_rows = training_data[\"Rating\"] == 0\n",
        "df_train_pos = training_data.loc[~neg_rows]\n",
        "df_train_neg = training_data.loc[neg_rows]\n",
        "# Merge the balanced data\n",
        "df_train = pd.concat([df_train_pos.sample(n = len(df_train_neg), random_state=42), df_train_neg], axis = 0)\n",
        "# Shuffle the order of training samples\n",
        "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop=True)\n",
        "print(\"Training set prevalence (n = {:d}):\".format(len(df_train)), \"{:.2f}%\".format((df_train[\"Rating\"].sum()/len(df_train))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5z0MJd6WO6yC"
      },
      "outputs": [],
      "source": [
        "### Create preproc and training and testing datasets   \n",
        "start = time.time()\n",
        "(x_train_concatGR, y_train_concatGR), (x_val_concatGR, y_val_concatGR), preproc_concatGR = txt.texts_from_array(x_train = list(df_train[\"Review\"]),\n",
        "                                                                                                 y_train = list(df_train[\"Rating\"]),\n",
        "                                                                                                 x_test = list(X_val_Goodreads_concat),\n",
        "                                                                                                 y_test = list(y_val_Goodreads_concat),\n",
        "                                                                                                 class_names = ['0','1'],\n",
        "                                                                                                 preprocess_mode = 'bert',\n",
        "                                                                                                 ngram_range=1,                    ### Change?\n",
        "                                                                                                 maxlen = 200)                     # Was 175          \n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKgOubqsO6yD"
      },
      "outputs": [],
      "source": [
        "### Define and train the model ###\n",
        "start = time.time()\n",
        "model_concatGR = txt.text_classifier(name='bert',\n",
        "                             train_data=(x_train_concatGR, y_train_concatGR),\n",
        "                             preproc=preproc_concatGR)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GS09yq3O6yD"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_concatGR = ktrain.get_learner(model=model_concatGR,\n",
        "                             train_data=(x_train_concatGR, y_train_concatGR),\n",
        "                             val_data=(x_val_concatGR, y_val_concatGR),\n",
        "                             batch_size=16)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpXZGZcRO6yD"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "learner_concatGR.fit_onecycle(lr=2e-5,\n",
        "                     epochs=3)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions on the Goodreads concatenated reviews:"
      ],
      "metadata": {
        "id": "dd87QTNidMbt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpkRZ5Am_OT4"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predictor_concatGR = ktrain.get_predictor(learner_concatGR.model, preproc_concatGR)\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa3U8iUC5fD8"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "predicted_ratings_concatGR = predictor_concatGR.predict(list(X_test_Goodreads_concat))\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubvB5HlU5fD9"
      },
      "outputs": [],
      "source": [
        "#How many reviews were in the test set?\n",
        "len(y_test_Goodreads_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF7wIMa-5fD9"
      },
      "outputs": [],
      "source": [
        "#How many of the reviews in the test set were actually negative?\n",
        "num_neg = 0\n",
        "for i in range(len(y_test_Goodreads_concat)):\n",
        "  if list(y_test_Goodreads_concat)[i] == 0:\n",
        "    num_neg = num_neg + 1\n",
        "num_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62q1_puK5fD8"
      },
      "outputs": [],
      "source": [
        "#How many of the predictions were correct?\n",
        "num_correct = 0\n",
        "for i in range(len(predicted_ratings_concatGR)):\n",
        "  if int(predicted_ratings_concatGR[i]) == list(y_test_Goodreads_concat)[i]:\n",
        "    num_correct = num_correct + 1\n",
        "num_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut8-m1Tk5fD9"
      },
      "outputs": [],
      "source": [
        "#What proportion of the predictions were correct?\n",
        "num_correct/len(list(y_test_Goodreads_concat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_V8rp4f5fD9"
      },
      "outputs": [],
      "source": [
        "#How many of the positive predictions were correct?\n",
        "num_1s_correct = 0\n",
        "for i in range(len(predicted_ratings_concatGR)):\n",
        "  if int(predicted_ratings_concatGR[i]) == list(y_test_Goodreads_concat)[i] and int(predicted_ratings_concatGR[i]) == 1:\n",
        "    num_1s_correct = num_1s_correct + 1\n",
        "num_1s_correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3wsbHwR5fD9"
      },
      "outputs": [],
      "source": [
        "#How many of the negative predictions were correct?\n",
        "num_0s_correct = 0\n",
        "for i in range(len(predicted_ratings_concatGR)):\n",
        "  if int(predicted_ratings_concatGR[i]) == list(y_test_Goodreads_concat)[i] and int(predicted_ratings_concatGR[i]) == 0:\n",
        "    num_0s_correct = num_0s_correct + 1\n",
        "num_0s_correct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All done!"
      ],
      "metadata": {
        "id": "Hyltz_hbdsIy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of NEURO_Final_Code_4_30.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8geq+EwVxU1acZqpsn77N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}